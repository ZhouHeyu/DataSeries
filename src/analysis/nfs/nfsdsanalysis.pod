=head1 NAME 

   nfsdsanalysis - perform analysis on NFS dataseries files

=head1 SYNOPSIS

   nfsdsanalysis [OPTION]... FILE...
   nfsdsanalysis [OPTION]... index.ds start-time end-time

=head1 DESCRIPTION

Each of the different options adds a module to the list of ones that
will be run over the set of files to be analyzed.  The set of files
may be selected either by just listing them, or by generating an index
file and listing a start and end time in seconds.  The latter form is
useful when the number of files gets large because they may not all be
listable on a single command line.  

Classnames are given for each option to make it easier to find the
implementation in the code.

=head2 -a # classname OperationByFileHandle

This analysis is useful for finding files which are very commonly
accessed, the operations used on those files, and if the underlying
fileservers are NetApps, the filesystems which are commonly accessed.

In particular, the analysis counts the number of operations by
(operation,filename), (filename), (filesystem).  If no name is found,
the filehandle is substituted for the filename.  The filesystem
version of this rollup currently assumes the form of filesystem naming
that is used by the NetApp filers wherein the filesystem can be
determined by certain of the bytes in the filehandle.  That part of
the results will be garbage unless the underlying filesystem was
netapp.

This analysis can use a ton of memory because it's memory usage is
proportional to the number of unique (server, operation, filehandle)
pairs.  

Example output:

	FileSystem Rollup:
	Too many filesystems (>= 100000) filesystems found, assuming that fh->fs mapping is wrong
	
	FH Rollup:
	fhrollup: server 10.11.192.51, fh 12345608000003e7000a00000001d6ba20fd3d75000a00000000000200006765, fn *unknown*: 16 ops 0.102 MB, 398.312 us avg lat
	fhrollup: server 10.11.192.3, fh 12345634000003e7000a00000002fc06020f7777000a00000000000200000000, fn *unknown*: 6 ops 0.003 MB, 1103.167 us avg lat
	fhrollup: server 10.11.192.32, fh 1234562064c2bd0035df56002000000000251c212d495100c83700000138c000, fn 2f8f2f56269e884bf1e95bd4fc5d4fa7: 6 ops 0.001 MB, 1602.167 us avg lat
	fhrollup: server 10.11.192.110, fh 123456f000003e7000a000000033e976812f470000a0000000000020000604a, fn *unknown*: 3 ops 0.004 MB, 915.000 us avg lat
	fhrollup: server 10.11.192.110, fh 123456f000003e7000a00000003709c5acf3e18000a0000000000020000604a, fn *unknown*: 3 ops 0.004 MB, 1374.000 us avg lat
	...
	
	FH/Op Rollup:
	fhoprollup: server 10.11.224.74, op read, fh 123456aa050000008230303006002f0c011700028292c2f9dbdf97d707ce49c50200bf0c8d1e000603005f0cb51d0006, fn *unknown*: 8 ops 0.007 MB, 139.125 us avg lat
	fhoprollup: server 10.11.192.4, op write, fh 123456a000003e7000a000000025ac37224787b000a000000000002000007c3, fn *unknown*: 69 ops 0.009 MB, 2306.565 us avg lat
	fhoprollup: server 10.11.224.10, op read, fh 123456050000008230303004002f0e2d1c00027bbab53417280d9b7a5a591f00003f0ed91f000600003f0e4f1f0006, fn *unknown*: 46 ops 0.176 MB, 192.565 us avg lat
	...

=head2 -b # classname UniqueBytesInFilehandles

This analysis finds bytes which have a small number of unique values
in filehandles.  This is important if we are going to do a re-encoding
of filehandles for a caching system because we would need to store
additional data (such as the origin server), and if there are bytes
with few unique values, then we could use those bytes for encoding the
additional information.

=head2 -c <recent-age-seconds> # classname FileageByFilehandle

This analysis is useful for estimating how rapidly data is changing.
In particular, it examines all of the filehandles in the trace, and
for each one finds the maximum size of the file, and the most recent
modify time relative to the packet arrival time, or alternately, the
age of the file at the time of the operation.  It then prints out the
top 20 most recently modified files, and a summary of the number of
filehandles found, the number of recent ones, and the maximum MB of
source data that could have been accessed and the fraction of that
which is recent. It also prints out the first filename associated with
a filehandle in the trace (if any).

Note that this analysis has the downside that if a filehandle is being
repeatedly overwritten (either by deletes and re-use of the
filehandle, or by explicit overwrites) that the analysis could
underestimate the amount of data that needs to be transferred.  Also
note that you may get negative times for recent accesses; this is
because the timestamp on the packet is generated by the tracing
machine, but the timestamp in the file is generated by the client or
server.  Clock skew effectively causes an offset to these numbers.

This operation can use a ton of memory because the memory usage is
proportional to the number of unique filehandles.  A possible bug in
this implementation is that it doesn't include the server as part of
the uniquification of file handles.  This is correct for NetApp
systems with caches as the caches just pass through the filehandle,
but is incorrect in other systems.

Example output:

	Begin-virtual void FileageByFilehandle::printResult()
	   -44.499 secs 024da5e0000003e7000a000000058d4c56d7c9db000a00000000000200006b86            *unknown*     file 532480
	   -44.499 secs 024cfdea000003e7000a0000000230637e996877000a000000000002000007c3            *unknown*     file 11186176
	   -44.499 secs 024cfdea000003e7000a00000002ea4c1f0c7043000a000000000002000007c3            *unknown*     file 1802240
	   -44.499 secs 024cfdea000003e7000a00000002e9cb45b23cde000a000000000002000007c3            *unknown*     file 11084
	   ...
	271007 unique filehandles, 50609 recent: 189443.23 MB total files accessed; 59311.59 MB recent, or 31.31%
	End-virtual void FileageByFilehandle::printResult()

=head2 -d

Large file write analysis by file handle

=head2 -e

Large file write analysis by file name

=head2 -f

Large file analysis by file handle

=head2 -g

Large file analysis by file name

=head2 -h

Help -- Generate usage summary

=head2 -i # classname NFSOpPayload

This analysis is useful for examining how many requests and bytes each
of the different nfs operations are transferring, for example to
estimate how fast a proxy/cache would have to be to keep up.  In
particular, for each request or response, this analysis accumulates
the payload size separately for the TCP/UDP transport choice,
operation type, and request/reply direction.

Example Output:

	Begin-virtual void NFSOpPayload::printResult()
	TCP         read   Reply: 248724.709 MB, 17555.72 bytes/op, 32872 max bytes/op, 14855939 ops
	TCP        write Request: 30236.439 MB, 6058.29 bytes/op, 32824 max bytes/op, 5233360 ops
	TCP      getattr   Reply: 2804.244 MB,  88.00 bytes/op,   88 max bytes/op, 33414358 ops


=head2 -j # classname ServerLatency

This analysis is useful for determining the number of operations and
latency for each of the various servers in the trace.  In particular,
for each request/response pair, it accumulates the latency of the
operation for each server and operation.  It rolls the results up into
by server, by operation, and overall.  The data under the duplicates
line tells you quantiles for the delay between duplicates if any
existed.  The code currently calculates the latency from the first
request to each reply.  This emulates the delay seen by the client.
The code has support for calculating the latency from the last
request, which provides more information on how the server generating
latency, but that code is currently disabled.

Example Output:

Begin-virtual void ServerLatency::printResult()
 id: server ip
001: 10.11.8.37
002: 10.11.9.21

0 missing requests, 0 missing replies; 0.00ms mean est firstlat, 0.00ms mean est lastlat
duplicates: 0 replies, 0 requests; delays min=infms
0 data points, mean 0 +- 0 [inf,-inf]

Grouped by (Server,Operation) pair:
server operation   #ops  #dups mean ; firstlat mean 50% 90% 
001   getattr         2      0 0.00 ;   1.208   1.21   1.21 
001    statfs         7      0 0.00 ;   0.349   0.23   1.25 
002    statfs         3      0 0.00 ;   0.989   1.35   1.35 

Grouped by Server:
server operation   #ops  #dups mean ; firstlat mean 50% 90% 
001         *         9      0 0.00 ;   0.540   0.27   1.25 
002         *         3      0 0.00 ;   0.989   1.35   1.35 

Grouped by Operation:
server operation   #ops  #dups mean ; firstlat mean 50% 90% 
 *    getattr      3358      0 0.00 ;   0.064   0.06   0.09 
 *     lookup      1124      0 0.00 ;   0.165   0.15   0.22 

Complete rollup:
server operation   #ops  #dups mean ; firstlat mean 50% 90% 
 *          *     10000      0 0.00 ;   0.135   0.10   0.20 
End-virtual void ServerLatency::printResult()

=head2 -k # classname ClientServerPairInfo

This analysis is useful for determining if the usage between clients
and servers is balanced, and if different clients use the same servers
in similar amounts.  In particular, for each Client/Server pair, this
analysis accumulates the payload size between the client and server.
It currently sorts the output by total payload size.

Example Output:

	protocol client server: total data ...
	TCP 10.11.220.132 10.11.192.110: 10510.290 MB, 7421.21 bytes/op, 32872 max bytes/op, 1485046 ops
	TCP 10.11.220.124 10.11.197.24: 3263.072 MB, 12325.62 bytes/op, 32872 max bytes/op, 277599 ops
	TCP 10.11.220.133 10.11.224.52: 1412.919 MB, 1900.68 bytes/op, 32872 max bytes/op, 779485 ops
	TCP 10.11.220.4 10.11.224.30: 1219.811 MB, 1765.50 bytes/op, 32872 max bytes/op, 724479 ops
	TCP 10.11.220.118 10.11.224.30: 1170.995 MB, 1584.63 bytes/op, 32872 max bytes/op, 774868 ops
	...

=head2 -l # classname HostInfo

This analysis looks at the amount of data and operations going either
in or out of each of the hosts.  It is useful for identifying heavily
used hosts.  In particular for each access, the payload size is
accumulated for both the source host and the destination host. 

Example Output:

	Begin-virtual void HostInfo::printResult()
	10.11.224.30: 33452.498 MB, 2033.51 bytes/op, 32872 max bytes/op, 17.250 million ops
	10.11.224.52: 30743.872 MB, 1618.75 bytes/op, 32872 max bytes/op, 19.915 million ops
	10.11.192.110: 27413.615 MB, 2637.69 bytes/op, 32872 max bytes/op, 10.898 million ops
	10.11.224.10: 21685.491 MB, 1444.86 bytes/op, 32872 max bytes/op, 15.738 million ops
	...

=head2 -m # classname PayloadInfo

This analysis looks at which transport protocols are primarily being
used to move the data in the system.  In particular for each request,
it accumulates the total bytes moved, and breaks this out into tcp and
udp transports.

Example Output:

	Begin-virtual void PayloadInfo::printResult()
	time range: 1091578148.32s .. 1091602813.35s = 24665.02s, 6.85hours
	payload_length: avg = 1717.90 bytes, stddev = 6556.1648 bytes, sum = 283.9577 GB, 11.7889MB/s, count=177.48 million 7.20 k/s
	payload_length(udp): avg = 99.06 bytes, stddev = 280.9744 bytes, sum = 0.9220 GB, 0.0383MB/s, count=9.99 million 0.41 k/s
	payload_length(tcp): avg = 1814.50 bytes, stddev = 6736.3013 bytes, sum = 283.0356 GB, 11.7506MB/s, count=167.49 million 6.79 k/s
	End-virtual void PayloadInfo::printResult()

=head2 -n # classname FileSizeByType

This analysis makes no sense; for each record, it adds up the size of
the thing referenced based on the type of the thing.  This stunningly
overcounts the size of files and directories, and at best is good for
telling you how many accesses were made to different types of things.

=head2 -o

Unbalanced operations analysis

=head2 -p

Time range analysis

=head2 -q

Read analysis

=head2 -r

Common bytes between filehandle and dirhandle

=head2 -s # classname SequentialWholeAccess

This analysis looks for patterns in how files are being accessed, in
particular, how many clients access the files, whether their accesses
are sequential or random, how many repeat accesses, and an estimate of
cache efficiency.

TODO: fill in details of analysis

This analysis is stunningly expensive in terms of memory because it
needs to maintain separate entries for every
(client,server,fh,read/write) pair to track all of the different
access patterns.

The code can print out complete individual client details, or do
rollups based on (server,filehandle) and based on mountpoint if the
fh->mountpoint mapping is correct.

Example output:


=head2 -t

Strange write search

=head2 -u

file handle lookup

=head2 -v I<1-5>

print series: 1 = common, 2 = attrops, 3 = rw, 4 = common/attr join, 5
= common/attr/rw join

=head2 -w

servers per filehandle

=head2 -x 

transactions

=head2 -y

outstanding requests

=head2 -z I<fh-list filename>

tmp file handle lookup

=head1 COPYRIGHT

(c) Copyright 2003-2007, Hewlett-Packard Development Company, LP

See the file named COPYING for license details
